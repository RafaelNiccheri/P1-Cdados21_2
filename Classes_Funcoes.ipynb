{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of length 2 with all words that wont be removed ['fantastico', 'fantÃ¡stico']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import typing\n",
    "import string\n",
    "import functools\n",
    "import operator\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "global Object_of_Study\n",
    "Object_of_Study = input('Input the object of this study below\\n>>> ')\n",
    "\n",
    "class ListWord:\n",
    "    \"\"\"\n",
    "Class that lists words in a given dataframe column\n",
    "    \"\"\"\n",
    "    def __init__(self, column_name=\"\", column_number=-1):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            column_name (str): name of the pandas.DataFrame column\n",
    "            column_number (int): number of the pandas.DataFrame column\n",
    "        \"\"\"\n",
    "        self.list_word = []\n",
    "        self.emoji_list = []\n",
    "        self.dataframe = 'dataframe'\n",
    "        self.column_name = str(column_name)\n",
    "        self.column_number = int(column_number)\n",
    "        self.standard_case = False\n",
    "    def _b_c_n(self, dataframe, start_list, stop_list, only_word):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): dataframe to be listed\n",
    "            start_list (int): number of the row where the function should start\n",
    "            stop_list (int): number of the row where the function should stop\n",
    "            only_word (boolean): if true removes all items that have something other then letters\n",
    "\n",
    "        \"\"\"\n",
    "        for i in np.arange(start_list, stop_list):\n",
    "            splitting_emoji_string = emoji.get_emoji_regexp().split(str(dataframe[self.column_name][i]))\n",
    "            splitting_grouped_string = [j.split() for j in splitting_emoji_string]\n",
    "            uniting_sting_lists = functools.reduce(operator.concat, splitting_grouped_string)\n",
    "            if only_word:\n",
    "                removing_not_word = [j for j in uniting_sting_lists if j.isalpha()]\n",
    "                if self.standard_case:\n",
    "                    self.list_word += removing_not_word.lower()\n",
    "                else:\n",
    "                    self.list_word += removing_not_word.lower()\n",
    "            else:\n",
    "                if self.standard_case:\n",
    "                    self.list_word += uniting_sting_lists\n",
    "                else:\n",
    "                    self.list_word += uniting_sting_lists\n",
    "    def by_column_name(self, dataframe, start_list, stop_list, only_word=False):\n",
    "        \"\"\"\n",
    "        lists all words in a specified section of a pandas.DataFrame\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): dataframe to be listed\n",
    "            start_list (int): number of the row where the function should start\n",
    "            stop_list (int): number of the row where the function should stop\n",
    "            only_word (boolean): if True keep only words\n",
    "\n",
    "        Returns:\n",
    "            list: list of words\n",
    "        \"\"\"\n",
    "        if only_word:\n",
    "            print(\n",
    "                f\"only_word is set to {only_word}. Are you sure you only want to keep words you can get \"\n",
    "                f\"back emoji latter\")\n",
    "        self._b_c_n(dataframe, start_list, stop_list, only_word)\n",
    "        return self.list_word\n",
    "\n",
    "    def by_column_number(self, dataframe, start_list, stop_list, only_word=False):\n",
    "        \"\"\"\n",
    "        lists all words in a specified section of a pandas.DataFrame\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): dataframe to be listed\n",
    "            start_list (int): number of the row where the function should start\n",
    "            stop_list (int): number of the row where the function should stop\n",
    "            only_word (boolean): if True keep only words\n",
    "\n",
    "        Returns:\n",
    "            list: list of words\n",
    "        \"\"\"\n",
    "        for i in np.arange(start_list, stop_list):\n",
    "            splitting_emoji_string = emoji.get_emoji_regexp().split(str(dataframe.iloc[i, self.column_number]))\n",
    "            splitting_grouped_string = [j.split() for j in splitting_emoji_string]\n",
    "            uniting_sting_lists = functools.reduce(operator.concat, splitting_grouped_string)\n",
    "            if only_word:\n",
    "\n",
    "                removing_not_word = [j.lower() for j in uniting_sting_lists if j.isalpha()]\n",
    "                self.list_word += removing_not_word.lower()\n",
    "            else:\n",
    "                self.list_word += uniting_sting_lists.lower()\n",
    "        return self.list_word\n",
    "\n",
    "    def _l_e(self, dataframe, start_lists, stop_lists):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): dataframe to be listed\n",
    "            start_lists (int): number of the row where the function should start\n",
    "            stop_lists (int):  number of the row where the function should stop\n",
    "        \"\"\"\n",
    "        lista_emo1 = []\n",
    "        for i in np.arange(start_lists, stop_lists):\n",
    "            lista_emo1.append(''.join(j for j in str(dataframe[self.column_name][i]) if j in emoji.UNICODE_EMOJI['en']))\n",
    "            if '' in lista_emo1:\n",
    "                lista_emo1.remove('')\n",
    "        for i in lista_emo1:\n",
    "            lista_emo1_s = list(i)\n",
    "            for j in lista_emo1_s:\n",
    "                if j not in self.list_word:\n",
    "                    self.emoji_list.append(j)\n",
    "\n",
    "    def list_emoji(self, dataframe, start_list, stop_list):\n",
    "        \"\"\"\n",
    "        lists all emojis in a specified section of a pandas.DataFrame\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): dataframe to be listed\n",
    "            start_list (int): number of the row where the function should start\n",
    "            stop_list (int): number of the row where the function should stop\n",
    "\n",
    "        Returns:\n",
    "            list: list of all emoji in the dataframe\n",
    "        \"\"\"\n",
    "        self._l_e(dataframe, start_lists=start_list, stop_lists=stop_list)\n",
    "        return self.emoji_list\n",
    "\n",
    "    def lists_all(self, dataframe, c_o_c=False, standard_case=False, new_column_name='# of occurrences'):\n",
    "        \"\"\"\n",
    "        lists all words and emojis in a specified section of a pandas.DataFrame\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): dataframe to be listed\n",
    "            c_o_c (boolean): if True calls count_list_occurrence\n",
    "            standard_case (str): standardize the casing of the words\n",
    "            new_column_name (str): if c_o_c is True defines the name of the new dataframe column\n",
    "\n",
    "        Returns:\n",
    "            typing.Union[list, pandas.DataFrame]: list of all words + emoji in the dataframe or dataframe with each\n",
    "              words + emoji as a index and the occurrence of each item as a column\n",
    "        \"\"\"\n",
    "        self._l_e(dataframe, 0, len(dataframe))\n",
    "        if standard_case:\n",
    "            self.standard_case = standard_case\n",
    "        self._b_c_n(dataframe, 0, len(dataframe), only_word=False)\n",
    "        if c_o_c:\n",
    "            c_l_o = self.emoji_list + self.list_word\n",
    "            self.count_list_occurrence(c_l_o, dic_obj={}, creat_dataframe=True, new_column_name=new_column_name)\n",
    "            return self.dataframe\n",
    "        else:\n",
    "            return self.emoji_list + self.list_word\n",
    "\n",
    "    def count_list_occurrence(self, list_obj, dic_obj=None, creat_dataframe=False, new_column_name='# of occurrences'):\n",
    "        \"\"\"\n",
    "        counts the number of times each item appears in a list\n",
    "\n",
    "        Args:\n",
    "            list_obj (list): list of any object type\n",
    "            dic_obj (typing.Optional[dict]): dictionary in witch to count occurrences. Read as (items:occurrences)\n",
    "            creat_dataframe (boolean): if True it returns a pandas.DataFrame\n",
    "            new_column_name (str): name of the new dataframe column\n",
    "\n",
    "        Returns:\n",
    "            typing.Union[dict(items, int), pandas.DataFrame]: dictionary with  the occurrence of each item or pandas.\n",
    "              DataFrame with the occurrence of each item as a column\n",
    "        \"\"\"\n",
    "        if dic_obj is None:\n",
    "            dic_obj = {}\n",
    "        set_dic = set(dic_obj.keys())\n",
    "        set_list = set(list_obj)\n",
    "        for pp in set_list:\n",
    "            if pp not in set_dic:\n",
    "                dic_obj[pp] = 0\n",
    "        for z in list_obj:\n",
    "            dic_obj[z] += 1\n",
    "        if creat_dataframe:\n",
    "            new_dataframe = pd.DataFrame.from_dict(dic_obj, orient='index', columns=[new_column_name])\n",
    "            self.dataframe = new_dataframe\n",
    "        else:\n",
    "            return dic_obj\n",
    "\n",
    "\n",
    "class RemoveWords:\n",
    "    \"\"\"\n",
    "class that has 6 different types of filters for strings and a seventh filter that allows the selection of multiple filters\n",
    "at once\n",
    "    \"\"\"\n",
    "    list_desired_words = [Object_of_Study]\n",
    "    while True:\n",
    "        Desired_Study_Words = str(input(\n",
    "            f\"\"\"Enter words you don't want removed individually or separated by space, all words\n",
    "    entered are case matched to lowercase. Type {Object_of_Study} to leave: \"\"\"))\n",
    "        if '' in list_desired_words:\n",
    "            list_desired_words.remove('')\n",
    "        if Desired_Study_Words == Object_of_Study:\n",
    "            break\n",
    "        elif ' ' in Desired_Study_Words:\n",
    "            split_input = [j for j in Desired_Study_Words.split()]\n",
    "            for j in split_input:\n",
    "                j = j.lower()\n",
    "                list_desired_words.append(j)\n",
    "        else:\n",
    "            list_desired_words.append(Desired_Study_Words.lower())\n",
    "    print(\n",
    "        f'Here is a list of length {len(list_desired_words)} with all words that wont be removed {list_desired_words}')\n",
    "\n",
    "    def __init__(self, dataframe, column_name, show_removed=False):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): dataframe to be filtered\n",
    "            column_name (str): name of the pandas.DataFrame column\n",
    "            show_removed (boolean): if True shows a list of all removed words\n",
    "        \"\"\"\n",
    "\n",
    "        self.column_name = str(column_name)\n",
    "        self.dataframe = dataframe\n",
    "        self.data = self.dataframe.to_dict()\n",
    "        self.remove_all = False\n",
    "        self.filtered = ''\n",
    "        self.removed = []\n",
    "        self.show_removed = show_removed\n",
    "        self.emo_db = emoji.UNICODE_EMOJI['en']\n",
    "        self.Object_of_Study = Object_of_Study\n",
    "        self.new_dic = {}\n",
    "\n",
    "    def _filter_simple(self, key_word='', length_st=0):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            key_word (str): character which all words containing will be removed\n",
    "            length_st (int): maximum length of the removed word\n",
    "        \"\"\"\n",
    "        keep_dic = {}\n",
    "        data2 = self.data[self.column_name]\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        for elements in data2.keys():\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif length_st > len(elements):\n",
    "                self.removed.append(elements)\n",
    "            elif key_word == '@' or key_word == 'http':\n",
    "                if key_word in elements:\n",
    "                    self.removed.append(elements)\n",
    "                else:\n",
    "                    keep_dic[elements] = data2[elements]\n",
    "            else:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "\n",
    "    def remove_at(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: A dataframe without words with '@'\n",
    "        \"\"\"\n",
    "        self._filter_simple(key_word='@')\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_link(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: dataframe without links\n",
    "        \"\"\"\n",
    "        self._filter_simple(key_word='http')\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_ponc(self, punks=string.punctuation):\n",
    "        \"\"\"\n",
    "        removes chosen characters from given strings wile keeping the string\n",
    "\n",
    "        Args:\n",
    "            punks (str): string of all chars to be removed\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: dataframe without chosen characters\n",
    "        \"\"\"\n",
    "\n",
    "        removeing = list(punks)\n",
    "        keep_dic = {}\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        data2 = self.data[self.column_name]\n",
    "        for elements in data2.keys():\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            else:\n",
    "                removing_puncs_s = ''.join(ch for ch in elements if ch not in removeing)\n",
    "                if removing_puncs_s in list(keep_dic.keys()):\n",
    "                    keep_dic[removing_puncs_s] = data2[elements] + keep_dic[removing_puncs_s]\n",
    "                else:\n",
    "                    keep_dic[removing_puncs_s] = data2[elements]\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_laugh(self, length_k, length_no_k):\n",
    "        \"\"\"\n",
    "        receives the minimum length of k's together for the removal of a string to be considered as well as the minimum\n",
    "        percentage of k's in order for its removal\n",
    "\n",
    "        Args:\n",
    "            length_k (int): minimum length of k's together for removal to be considered\n",
    "            length_no_k (int): minimum percentage of the string left after removing k's\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: dataframe without k's\n",
    "        \"\"\"\n",
    "        keep_dic = {}\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        data2 = self.data[self.column_name]\n",
    "        for elements in data2.keys():\n",
    "            string_nok = \"\"\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif 'k' * length_k in elements:\n",
    "                list_wk = list(elements)\n",
    "                for khas in list_wk:\n",
    "                    if khas != \"k\":\n",
    "                        string_nok += khas\n",
    "                string_k_percent = (1 - (len(string_nok) / len(elements))) * 100\n",
    "                if round(string_k_percent) > length_no_k:\n",
    "                    self.removed.append(string_nok)\n",
    "                    pass\n",
    "                else:\n",
    "                    keep_dic[string_nok] = data2[elements]\n",
    "            else:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_word_sts(self, length_s):\n",
    "        \"\"\"\n",
    "        removes all words smaller than length_s\n",
    "\n",
    "        Args:\n",
    "            length_s (int): minimum length of words\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: dataframe without words smaller than length_s\n",
    "        \"\"\"\n",
    "        self._filter_simple(length_st=length_s)\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_num_str(self, length_num_c, percent_str_num=100):\n",
    "        \"\"\"\n",
    "        removes all sequence of number larger then length_num_c\n",
    "\n",
    "        Args:\n",
    "            percent_str_num (int): maximum percent of a string that can be and int\n",
    "            length_num_c (int): length of sequenced numbers in a string required for the string to be removed\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: pandas.DataFrame without strings with the specified minimum length of of sequenced numbers\n",
    "        \"\"\"\n",
    "        keep_dic = {}\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        data2 = self.data[self.column_name]\n",
    "        for elements in data2.keys():\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif len(elements) < length_num_c:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            else:\n",
    "                percent_num=[i for i in elements if i in list('1234567890')]\n",
    "                if len(percent_num)*100/len(elements) > percent_str_num:\n",
    "                    self.removed.append(elements)\n",
    "                for i in range(0, len(elements)):\n",
    "                    k = length_num_c\n",
    "                    k += i\n",
    "                    if k <= len(elements):\n",
    "                        slices_el = elements[i:k]\n",
    "                        try:\n",
    "                            if int(slices_el):\n",
    "                                self.removed.append(elements)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                if elements not in self.removed:\n",
    "                    keep_dic[elements] = data2[elements]\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_options(self, **kwargs):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            **kwargs: this parameter excepts any of the remove_* type function followed by a dictionary with its items as dictates the exemple\n",
    "              remove_*={boolean:\"(param)\"}, remove_laugh={True:\"(3, 5)\"} if you desire to pass a string as a param it should be\n",
    "              remove_*={boolean:\"('param')\"}, remove_ponc={True:\"('!@#$%^&*()')\"}\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: dataframe with filtered index accordance to Kwargs received\n",
    "        \"\"\"\n",
    "\n",
    "        list_o = ['remove_at', 'remove_link', 'remove_ponc', 'remove_word_sts', 'remove_laugh', 'remove_num_str']\n",
    "        list_f = ['self.remove_at', 'self.remove_link', 'self.remove_ponc', 'self.remove_word_sts', 'self.remove_laugh',\n",
    "                  'self.remove_num_str']\n",
    "        self.remove_all = True\n",
    "        for choice in list_o:\n",
    "            try:\n",
    "                choice_tf = list(kwargs[choice].keys())\n",
    "                if choice_tf[0]:\n",
    "                    getting_pos = list_o.index(choice)\n",
    "                    choice_ff = list(kwargs[choice].values())\n",
    "                    eval(list_f[getting_pos] + str(choice_ff[0]))\n",
    "                    if self.show_removed:\n",
    "                        print(choice, self.removed)\n",
    "            except Exception:\n",
    "                continue\n",
    "        if self.show_removed:\n",
    "            print('Total', self.removed)\n",
    "        self.filtered = pd.DataFrame.from_dict(self.new_dic)\n",
    "        return self.filtered\n",
    "\n",
    "def unite_dataframes_col(df1, df2, col1_title, col2_title, replace_nan=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        df1 (pandas.DataFrame): dataframe to be united\n",
    "        df2 (pandas.DataFrame): dataframe to be united\n",
    "        col1_title (str): title  of  the columns that came from this dataframe\n",
    "        col2_title (str): title  of  the columns that came from this dataframe\n",
    "        replace_nan (typing.Optional[int, str]): If not nan replaces NAN for whatever its set to\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: united pandas.DataFrame\n",
    "    \"\"\"\n",
    "    df3 = pd.concat([df1, df2], axis=1, keys=[str(col1_title), str(col2_title)])\n",
    "    if replace_nan is not None:\n",
    "        df3 = df3.fillna(replace_nan)\n",
    "    return df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}