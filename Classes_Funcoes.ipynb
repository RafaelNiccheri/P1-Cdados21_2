{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of length 2 with all words that wont be removed ['fantastico', 'fantástico']\n",
      "['E:\\\\Projetos\\\\Py-Charm\\\\Cdados\\\\Projetos\\\\P1-Cdados21_2\\\\venv\\\\Scripts', 'C:\\\\Windows\\\\system32', 'C:\\\\Windows', 'C:\\\\Windows\\\\System32\\\\Wbem', 'C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\', 'C:\\\\Windows\\\\System32\\\\OpenSSH\\\\', 'C:\\\\Program Files\\\\Git\\\\cmd', 'C:\\\\Program Files\\\\dotnet\\\\', 'D:\\\\Program Files\\\\Siemens\\\\NX1980\\\\CAPITALINTEGRATION\\\\capitalnxremote\\\\', 'C:\\\\Users\\\\Rafa\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import functools\n",
    "import operator\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "global Object_of_Study\n",
    "Object_of_Study = input('Input the object of this study below\\n>>> ')\n",
    "\n",
    "class ListWord:\n",
    "    def __init__(self, column_name=\"\", column_number=-1):\n",
    "        \"\"\"\n",
    "\n",
    "        :param column_number: number of the pandas.DataFrame column\n",
    "        :type column_number: int\n",
    "        :param column_name: name of the pandas.DataFrame\n",
    "        :type column_name: str\n",
    "        \"\"\"\n",
    "        self.list_word = []\n",
    "        self.emoji_list = []\n",
    "        self.dataframe = 'dataframe'\n",
    "        self.column_name = str(column_name)\n",
    "        self.column_number = int(column_number)\n",
    "    def _b_c_l(self, dataframe, start_list, stop_list, only_word):\n",
    "        \"\"\"\n",
    "        :param dataframe: pandas.DataFrame to be listed\n",
    "        :type dataframe: pandas.DataFrame\n",
    "        :param start_list: number of the row\n",
    "        where the function should start\n",
    "        :type start_list: int\n",
    "        :param stop_list: number of the row\n",
    "        where the function should end\n",
    "        :type stop_list: int\n",
    "        :param only_word: if true removes all items that\n",
    "        have something other then letters\n",
    "        :type only_word: Boolean\n",
    "        \"\"\"\n",
    "        for i in np.arange(start_list, stop_list):\n",
    "            splitting_emoji_string = emoji.get_emoji_regexp().split(dataframe[self.column_name][i])\n",
    "            splitting_grouped_string = [j.split() for j in splitting_emoji_string]\n",
    "            uniting_sting_lists = functools.reduce(operator.concat, splitting_grouped_string)\n",
    "            if only_word:\n",
    "                removing_not_word = [j for j in uniting_sting_lists if j.isalpha()]\n",
    "                self.list_word += removing_not_word\n",
    "            else:\n",
    "                self.list_word += uniting_sting_lists\n",
    "\n",
    "    def by_column_name(self, dataframe, start_list, stop_list, only_word=False):\n",
    "        \"\"\"\n",
    "\n",
    "        :type dataframe: pandas.DataFrame\n",
    "        :type start_list: int\n",
    "        :type stop_list: int\n",
    "        :type only_word: Boolean\n",
    "        :param only_word: if True keep only words\n",
    "        :param dataframe: pandas.Data\n",
    "        :param start_list: number of the row\n",
    "        where the function should start\n",
    "        :param stop_list: number of the row\n",
    "        where the function should stop\n",
    "        :return: list of words from specified\n",
    "        pandas.DataFrame rows and column\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        if only_word:\n",
    "            print(\n",
    "                f\"only_word is set to {only_word}. Are you sure you only want to keep words you can get \"\n",
    "                f\"back emoji latter\")\n",
    "        self._b_c_l(dataframe, start_list, stop_list, only_word)\n",
    "        return self.list_word\n",
    "\n",
    "    def by_column_number(self, dataframe, start_list, stop_list, only_word=False):\n",
    "        \"\"\"\n",
    "\n",
    "        :type dataframe: pandas.DataFrame\n",
    "        :type start_list: int\n",
    "        :type stop_list: int\n",
    "        :type only_word: Boolean\n",
    "        :param only_word: if True keep only words\n",
    "        :param dataframe: pandas.DataFrame\n",
    "        :param start_list: where\n",
    "        :param stop_list:\n",
    "        :return: list of words from specified\n",
    "        pandas.DataFrame rows and column\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        for i in np.arange(start_list, stop_list):\n",
    "            splitting_emoji_string = emoji.get_emoji_regexp().split(dataframe.iloc[i, self.column_number])\n",
    "            splitting_grouped_string = [j.split() for j in splitting_emoji_string]\n",
    "            uniting_sting_lists = functools.reduce(operator.concat, splitting_grouped_string)\n",
    "            if only_word:\n",
    "                removing_not_word = [j for j in uniting_sting_lists if j.isalpha()]\n",
    "                self.list_word += removing_not_word\n",
    "            else:\n",
    "                self.list_word += uniting_sting_lists\n",
    "        return self.list_word\n",
    "\n",
    "    def _l_e(self, dataframe, start_lists, stop_lists):\n",
    "        \"\"\"\n",
    "        :type dataframe: pandas.DataFrame\n",
    "        :type start_lists: int\n",
    "        :type stop_lists: int\n",
    "        :param dataframe: pandas.DataFrame\n",
    "        :param start_lists: number of the row\n",
    "        where the function should start\n",
    "        :param stop_lists: number of the row\n",
    "        where the function should end\n",
    "        \"\"\"\n",
    "        lista_emo1 = []\n",
    "        for i in np.arange(start_lists, stop_lists):\n",
    "            lista_emo1.append(''.join(j for j in dataframe[self.column_name][i] if j in emoji.UNICODE_EMOJI['en']))\n",
    "            if '' in lista_emo1:\n",
    "                lista_emo1.remove('')\n",
    "        for i in lista_emo1:\n",
    "            lista_emo1_s = list(i)\n",
    "            for j in lista_emo1_s:\n",
    "                self.emoji_list.append(j)\n",
    "\n",
    "    def list_emoji(self, dataframe, start_list, stop_list):\n",
    "        \"\"\"\n",
    "\n",
    "        :param start_list: number of the row\n",
    "        where the function should start\n",
    "        :type start_list: int\n",
    "        :param stop_list: number of the row\n",
    "        where the function should end\n",
    "        :type stop_list: int\n",
    "        :param dataframe: dataframe that will be listed\n",
    "        :type dataframe: pandas.DataFrame\n",
    "        :return: list of all emoji in the dataframe\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        self._l_e(dataframe, start_lists=start_list, stop_lists=stop_list)\n",
    "        return self.emoji_list\n",
    "\n",
    "    def lists_all(self, dataframe, c_o_c=False, standard_case=False):\n",
    "        \"\"\"\n",
    "\n",
    "        :param c_o_c: if True calls count_list_occurrence\n",
    "        :type c_o_c: Boolean\n",
    "        :param dataframe: pandas.DataFrame\n",
    "        :type dataframe: pandas.DataFrame\n",
    "        :param standard_case: standardize the casing of the\n",
    "        words (only works with create_dataframe True)\n",
    "        :type standard_case: Boolean\n",
    "        :return: list of all words + emoji in the dataframe.\n",
    "        :rtype: list.\n",
    "        \"\"\"\n",
    "        self._l_e(dataframe, 0, len(dataframe))\n",
    "        self._b_c_l(dataframe, 0, len(dataframe), only_word=False)\n",
    "        if c_o_c:\n",
    "            c_o_c_l = self.emoji_list + self.list_word\n",
    "            if standard_case:\n",
    "                self.count_list_occurrence(c_o_c_l, dic_obj={}, creat_dataframe=True, standard_case=True)\n",
    "            else:\n",
    "                self.count_list_occurrence(c_o_c_l, dic_obj={}, creat_dataframe=True)\n",
    "            return self.dataframe\n",
    "        else:\n",
    "            return self.emoji_list + self.list_word\n",
    "\n",
    "    # def c_o_f(self, dataframe):\n",
    "    #     \"\"\"\n",
    "    #\n",
    "    #     :rtype: pandas.DataFrame\n",
    "    #     \"\"\"\n",
    "    #     self.lists_all(dataframe, c_o_c=True)\n",
    "    #     return self.dataframe\n",
    "\n",
    "    def count_list_occurrence(self, list_obj, dic_obj=None, creat_dataframe=False, standard_case=False):\n",
    "        \"\"\"\n",
    "\n",
    "        :param creat_dataframe: if True it returns a pandas.DataFrame\n",
    "        :type creat_dataframe: Boolean\n",
    "        :param list_obj: list of any object type\n",
    "        :type list_obj: list\n",
    "        :param dic_obj: dictionary in witch to\n",
    "        count occurrences. If it´s not passed,\n",
    "        creates a new one. If a existing one is passed\n",
    "        it will be read as (key:value), (items:occurrences).\n",
    "        :type dic_obj: dictionary\n",
    "        :param standard_case: standardize the casisng of the\n",
    "        words (only works with create_dataframe True)\n",
    "        :type standard_case: Boolean\n",
    "        :return: a new dict as (keys:values), (items:occurrences).\n",
    "        if a existing dict is given it will make a copy of it and alter\n",
    "        only the copy. If creat_dataframe is True returns a pandas.DataFrame\n",
    "        created from these new dictionary\n",
    "        :rtype: dict or pandas.DataFrame\n",
    "        \"\"\"\n",
    "        if dic_obj is None:\n",
    "            dic_obj = {}\n",
    "        set_dic = set(dic_obj.keys())\n",
    "        set_list = set(list_obj)\n",
    "        for pp in set_list:\n",
    "            if pp not in set_dic:\n",
    "                dic_obj[pp] = 0\n",
    "        for z in list_obj:\n",
    "            dic_obj[z] += 1\n",
    "        if creat_dataframe:\n",
    "            new_dataframe = pd.DataFrame.from_dict(dic_obj, orient='index', columns=['# de ocorrências'])\n",
    "            if standard_case:\n",
    "                self.dataframe = new_dataframe\n",
    "            else:\n",
    "                self.dataframe = new_dataframe\n",
    "        else:\n",
    "            return dic_obj\n",
    "\n",
    "\n",
    "class RemoveWords:\n",
    "    list_desired_words = [Object_of_Study]\n",
    "    while True:\n",
    "        Desired_Study_Words = str(input(\n",
    "            f\"\"\"Enter words you don't want removed individually or separated by space, all words\n",
    "    entered are case matched to lowercase. Type {Object_of_Study} to leave: \"\"\"))\n",
    "        if '' in list_desired_words:\n",
    "            list_desired_words.remove('')\n",
    "        if Desired_Study_Words == Object_of_Study:\n",
    "            break\n",
    "        elif ' ' in Desired_Study_Words:\n",
    "            split_input = [j for j in Desired_Study_Words.split()]\n",
    "            for j in split_input:\n",
    "                j = j.lower()\n",
    "                list_desired_words.append(j)\n",
    "        else:\n",
    "            list_desired_words.append(Desired_Study_Words.lower())\n",
    "    print(\n",
    "        f'Here is a list of length {len(list_desired_words)} with all words that wont be removed {list_desired_words}')\n",
    "\n",
    "    def __init__(self, dataframe, column_name, show_removed=False):\n",
    "        \"\"\"\n",
    "\n",
    "        :param show_removed: if True shows a list of all removed words\n",
    "        :type show_removed: Boolean\n",
    "        :param dataframe: Receives a pandas DataFrame\n",
    "        :type dataframe: pandas.DataFrame\n",
    "        :param column_name: specify the name of the pandas.DataFrame column\n",
    "        :type column_name: str\n",
    "        \"\"\"\n",
    "        self.column_name = str(column_name)\n",
    "        self.dataframe = dataframe\n",
    "        self.data = self.dataframe.to_dict()\n",
    "        self.remove_all = False\n",
    "        self.filtered = ''\n",
    "        self.removed = []\n",
    "        self.show_removed = show_removed\n",
    "        self.emo_db = emoji.UNICODE_EMOJI['en']\n",
    "        self.Object_of_Study = Object_of_Study\n",
    "        self.new_dic = {}\n",
    "\n",
    "    def filter_simple(self, key_word='', length_st=0):\n",
    "        \"\"\"\n",
    "\n",
    "        :param key_word: character wich you disere all words containing to be removed\n",
    "        :type key_word: str\n",
    "        :param length_st: maximum length of the removed word\n",
    "        :type length_st: int\n",
    "        \"\"\"\n",
    "        keep_dic = {}\n",
    "        data2 = self.data[self.column_name]\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        for elements in data2.keys():\n",
    "            elements_l = elements.lower()\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements_l in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif length_st > len(elements):\n",
    "                self.removed.append(elements)\n",
    "            elif key_word == '@' or key_word == 'http':\n",
    "                if key_word in elements:\n",
    "                    self.removed.append(elements)\n",
    "                else:\n",
    "                    keep_dic[elements] = data2[elements]\n",
    "            else:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "\n",
    "    def remove_at(self):\n",
    "        \"\"\"\n",
    "        :return: A dataframe without words with '@'\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self.filter_simple(key_word='@')\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_link(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return: dataframe without links\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self.filter_simple(key_word='http')\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_ponc(self, puncs=string.punctuation):\n",
    "        \"\"\"\n",
    "\n",
    "        :param puncs: string of all punctuation marks to be removed\n",
    "        :type puncs: str\n",
    "        :return: dataframe without chosen punctuation\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        removeing = list(puncs)\n",
    "        keep_dic = {}\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        data2 = self.data[self.column_name]\n",
    "        for elements in data2.keys():\n",
    "            elements_l = elements.lower()\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements_l in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            else:\n",
    "                removing_puncs_s = ''.join(ch for ch in elements if ch not in removeing)\n",
    "                if removing_puncs_s in list(keep_dic.keys()):\n",
    "                    keep_dic[removing_puncs_s] = data2[elements] + keep_dic[removing_puncs_s]\n",
    "                else:\n",
    "                    keep_dic[removing_puncs_s] = data2[elements]\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_laugh(self, length_k, length_no_k):\n",
    "        \"\"\"\n",
    "\n",
    "        :param length_no_k: minimum percentage of the string left after removing k's\n",
    "        :type length_no_k: int\n",
    "        :param length_k: minimum length of the laugh that is removed\n",
    "        :type length_k: int\n",
    "        :return: dataframe without k's in words with a lot of them in sequence\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        keep_dic = {}\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        data2 = self.data[self.column_name]\n",
    "        for elements in data2.keys():\n",
    "            string_nok = \"\"\n",
    "            elements_l = elements.lower()\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements_l in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif 'k' * length_k in elements_l:\n",
    "                list_wk = list(elements)\n",
    "                for khas in list_wk:\n",
    "                    if khas != \"k\":\n",
    "                        string_nok += khas\n",
    "                string_k_percent = (1 - (len(string_nok) / len(elements))) * 100\n",
    "                if round(string_k_percent) > length_no_k:\n",
    "                    self.removed.append(string_nok)\n",
    "                    pass\n",
    "                else:\n",
    "                    keep_dic[string_nok] = data2[elements]\n",
    "            else:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_word_sts(self, length_s):\n",
    "        \"\"\"\n",
    "\n",
    "        :param length_s: minimum length of words\n",
    "        :type length_s: int\n",
    "        :return: dataframe without words smaller than length_s\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self.filter_simple(length_st=length_s)\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_num_str(self, length_num_c):\n",
    "        \"\"\"\n",
    "\n",
    "        :param length_num_c: length of sequenced numbers\n",
    "        in a string required for the string to be removed\n",
    "        :type length_num_c: int\n",
    "        :return: pandas.DataFrame without strings with the\n",
    "        specified minimum length of of sequenced numbers\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        keep_dic = {}\n",
    "        self.new_dic = {self.column_name: keep_dic}\n",
    "        data2 = self.data[self.column_name]\n",
    "        for elements in data2.keys():\n",
    "            elements_l = elements.lower()\n",
    "            if elements in self.emo_db:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif elements_l in RemoveWords.list_desired_words:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            elif len(elements) <= length_num_c:\n",
    "                keep_dic[elements] = data2[elements]\n",
    "            else:\n",
    "                for i in range(0, len(elements)):\n",
    "                    k = length_num_c\n",
    "                    k += i\n",
    "                    if k <= len(elements):\n",
    "                        slices_el = elements[i:k]\n",
    "                        try:\n",
    "                            if int(slices_el):\n",
    "                                self.removed.append(elements)\n",
    "                        except Exception:\n",
    "                            keep_dic[elements] = data2[elements]\n",
    "        if self.remove_all:\n",
    "            self.data = self.new_dic\n",
    "        else:\n",
    "            if self.show_removed:\n",
    "                print(self.removed)\n",
    "            return pd.DataFrame.from_dict(self.new_dic)\n",
    "\n",
    "    def remove_options(self, **options_my_class):\n",
    "        \"\"\"\n",
    "\n",
    "        :param options_my_class: Kwargs that determine what remove_*\n",
    "        function will be called and give its parameters\n",
    "        :type options_my_class: dict example - remove_options(remove_at={True: '()'}, remove_laugh={True: '(4, 3)'})\n",
    "        :return: dataframe with filtered index accordance to Kwargs received\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        list_o = ['remove_at', 'remove_link', 'remove_ponc', 'remove_word_sts', 'remove_laugh', 'remove_num_str']\n",
    "        list_f = ['self.remove_at', 'self.remove_link', 'self.remove_ponc', 'self.remove_word_sts', 'self.remove_laugh',\n",
    "                  'self.remove_num_str']\n",
    "        self.remove_all = True\n",
    "        for choice in list_o:\n",
    "            choice_tf = list(options_my_class[choice].keys())\n",
    "            try:\n",
    "                if choice_tf[0]:\n",
    "                    getting_pos = list_o.index(choice)\n",
    "                    choice_ff = list(options_my_class[choice].values())\n",
    "                    eval(list_f[getting_pos] + str(choice_ff[0]))\n",
    "                    if self.show_removed:\n",
    "                        print(choice, self.removed)\n",
    "            except Exception:\n",
    "                continue\n",
    "        if self.show_removed:\n",
    "            print('Total', self.removed)\n",
    "        self.filtered = pd.DataFrame.from_dict(self.new_dic)\n",
    "        return self.filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def unite_dataframes_col(df1, df2, col1_title, col2_title, replace_nan=None):\n",
    "    \"\"\"\n",
    "    :type df1: pandas.DataFrame\n",
    "    :param df1: dataframe to be united\n",
    "    :type df2: pandas.DataFrame\n",
    "    :param df2: dataframe to be united\n",
    "    :type col1_title: str\n",
    "    :param col1_title: title  of  the columns that came from this dataframe\n",
    "    :type col2_title: str\n",
    "    :param col2_title: title  of  the columns that came from this dataframe\n",
    "    :type replace_nan: noneType\n",
    "    :param replace_nan: If not nan replaces NAN for whatever its set to\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df3 = pd.concat([df1, df2], axis=1, keys=[str(col1_title), str(col2_title)])\n",
    "    if replace_nan is not None:\n",
    "        df3 = df3.fillna(replace_nan)\n",
    "    return df3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}